# -*- coding: utf-8 -*-
"""URL DETECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Aniac9OYemOFlbegvTNNUIkNnyQWQykl
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import shap

# Load dataset
df = pd.read_csv("/content/phishing-dataset-variation.csv")

# 3. Separate features and target variable
X = df.drop(columns=["phishing"])  # Drop the target column
y = df["phishing"]  # Target variable

# Impute missing values in features using the median strategy
imputer = SimpleImputer(strategy='median')
X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

# Verify that missing values are handled
print("Missing values after preprocessing:")
print(X.isnull().sum())

# Standardize the features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Train Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, y_pred_rf)
print("Random Forest Accuracy:", rf_accuracy)
print("Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))

# Train XGBoost model
xgb_model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)
xgb_accuracy = accuracy_score(y_test, y_pred_xgb)
print("XGBoost Accuracy:", xgb_accuracy)
print("XGBoost Classification Report:")
print(classification_report(y_test, y_pred_xgb))

# Compare model performance using a bar chart
metrics = ['Precision', 'Recall', 'Accuracy']
rf_scores = [0.98, 0.98, rf_accuracy]
xgb_scores = [0.97, 0.97, xgb_accuracy]

x = np.arange(len(metrics))
bar_width = 0.3

plt.figure(figsize=(8, 5))
plt.bar(x - bar_width/2, rf_scores, bar_width, label='Random Forest', color='royalblue')
plt.bar(x + bar_width/2, xgb_scores, bar_width, label='XGBoost', color='darkorange')
plt.xlabel("Metrics")
plt.ylabel("Scores")
plt.title("Model Performance Comparison")
plt.xticks(x, metrics)
plt.legend()
plt.ylim(0.95, 1)  # Focus on the relevant range
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# If X_train is a NumPy array, extract feature names from the original dataset
if isinstance(X_train, np.ndarray):
    feature_names = df.columns[:-1]  # Assuming last column is the target variable
else:
    feature_names = X_train.columns.tolist()  # If it's already a DataFrame

# Get feature importance from Random Forest
rf_importance = rf_model.feature_importances_

# Get feature importance from XGBoost
xgb_importance = xgb_model.feature_importances_

feature_df = pd.DataFrame({
    'Feature': feature_names,
    'Random Forest Importance': rf_importance,
    'XGBoost Importance': xgb_importance
})

# Sort features by importance (using Random Forest for ordering)
feature_df = feature_df.sort_values(by='Random Forest Importance', ascending=False)

# Select only the top 10 most important features
top_features = feature_df.head(10)

# Plot the feature importance
plt.figure(figsize=(10, 6))
sns.barplot(data=top_features.melt(id_vars='Feature'), x='value', y='Feature', hue='variable', palette=['royalblue', 'darkorange'])
# Labels and title
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.title("Top 10 Important Features: Random Forest vs XGBoost")
plt.legend(title="Model")
plt.grid(axis="x", linestyle="--", alpha=0.7)

#global shap
import shap
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Convert X_train to DataFrame if needed
if isinstance(X_train, np.ndarray):
    X_train = pd.DataFrame(X_train, columns=feature_names)

# Reduce sample size for faster computation
X_sample = X_train.sample(300, random_state=42)  # selecting 300 sampes

# SHAP for Random Forest using TreeExplainer (Faster than KernelExplainer)
explainer_rf = shap.TreeExplainer(rf_model)
shap_values_rf = explainer_rf.shap_values(X_sample)

# SHAP for XGBoost
explainer_xgb = shap.TreeExplainer(xgb_model)
shap_values_xgb = explainer_xgb.shap_values(X_sample)

# Ensure SHAP values shape matches X_sample
shap_values_rf = shap_values_rf[1] if isinstance(shap_values_rf, list) else shap_values_rf
shap_values_xgb = shap_values_xgb[1] if isinstance(shap_values_xgb, list) else shap_values_xgb
shap_values_rf = shap_values_rf[:, :, 1]

# Plot SHAP summary for Random Forest
plt.title("SHAP Summary Plot - Random Forest")
shap.summary_plot(shap_values_rf, X_sample, feature_names=feature_names)

# Plot SHAP summary for XGBoost
plt.title("SHAP Summary Plot - XGBoost")
shap.summary_plot(shap_values_xgb, X_sample, feature_names=feature_names)

!pip install lime
import lime
import lime.lime_tabular
import numpy as np
import pandas as pd

# Convert X_train & X_test to DataFrame if they are NumPy arrays
if isinstance(X_train, np.ndarray):
    X_train = pd.DataFrame(X_train, columns=feature_names)

if isinstance(X_test, np.ndarray):
    X_test = pd.DataFrame(X_test, columns=feature_names)

# Create a LIME Explainer for tabular data
explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=X_train.values,  # Training data without labels
    feature_names=feature_names,  # Column names
    class_names=["Legit", "Phishing"],  # Target class names
    mode='classification'  # Classification mode
)

# Select a sample from test data for explanation
sample_index = 10  # Change this to analyze different samples
sample_data = X_test.iloc[sample_index].values.reshape(1, -1)  # Now it's correct

# Generate LIME explanation for Random Forest
exp_rf = explainer.explain_instance(
    sample_data[0], rf_model.predict_proba
)

# Generate LIME explanation for XGBoost
exp_xgb = explainer.explain_instance(
    sample_data[0], xgb_model.predict_proba
)

# Show explanations in notebook
print("LIME Explanation for Random Forest:")
exp_rf.show_in_notebook()

print("LIME Explanation for XGBoost:")
exp_xgb.show_in_notebook()

# Reset indexes for consistency
X_test = X_test.reset_index(drop=True)
y_test = y_test.reset_index(drop=True)

# Selection of phishing and legitimate samples
phishing_samples = X_test[y_test == 1].head(2)  # Select two phishing samples
legitimate_samples = X_test[y_test == 0].head(2)  # Select two safe samples

# Combine selected samples
selected_samples = pd.concat([phishing_samples, legitimate_samples])
selected_samples_index = selected_samples.index  # Saving indexes

print("Selected Sample Indexes:", selected_samples_index.tolist())

import shap
import lime
import lime.lime_tabular
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Check and convert X_test to DataFrame if needed
if isinstance(X_test, np.ndarray):
    X_test = pd.DataFrame(X_test, columns=feature_names)

X_test = X_test.reset_index(drop=True)
y_test = pd.Series(y_test).reset_index(drop=True)

# Select 2 phishing samples and 2 non-phishing samples
phishing_samples = X_test[y_test == 1].sample(2, random_state=42)
legitimate_samples = X_test[y_test == 0].sample(2, random_state=42)

selected_samples = pd.concat([phishing_samples, legitimate_samples]).reset_index(drop=True)
selected_labels = y_test.loc[selected_samples.index].reset_index(drop=True)

print("Selected Samples:\n", selected_samples)
print("Selected Labels:\n", selected_labels)

# Creating SHAP Explainer
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(selected_samples)

# Checking the expected_value
base_values = explainer.expected_value
if isinstance(base_values, np.ndarray):
    base_value_class_0 = base_values[0] if len(base_values) > 1 else base_values
    base_value_class_1 = base_values[1] if len(base_values) > 1 else base_values
else:
    base_value_class_0 = base_value_class_1 = base_values

# Draw SHAP Local chart for each sample
for i in range(len(selected_samples)):
    sample_class = selected_labels.iloc[i]

    if sample_class == 0:
        shap_explainer = shap.Explanation(
            values=shap_values[0][i],
            base_values=base_value_class_0,
            data=selected_samples.iloc[i]
        )
        title = f"SHAP Local Explanation for Sample {i+1} (Legitimate)"
    else:
        shap_explainer = shap.Explanation(
            values=shap_values[1][i],
            base_values=base_value_class_1,
            data=selected_samples.iloc[i]
        )
        title = f"SHAP Local Explanation for Sample {i+1} (Phishing)"

    plt.figure(figsize=(8, 5))
    shap.waterfall_plot(shap_explainer)
    plt.title(title)
    plt.show()

# Creating a LIME Explainer
lime_explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=X_test.values,
    feature_names=feature_names,
    class_names=["Legitimate", "Phishing"],
    mode="classification"
)

# LIME Local plot for each sample
for i in range(len(selected_samples)):
    exp = lime_explainer.explain_instance(
        data_row=selected_samples.iloc[i].values,
        predict_fn=rf_model.predict_proba,
        num_features=10
    )

    print(f"LIME Explanation for Sample {i+1}:")
    exp.show_in_notebook() # Display in notebook
    exp.as_pyplot_figure()
    plt.title(f"LIME Local Explanation for Sample {i+1}")
    plt.show()